---
title: "p8105_hw2_yl5219"
author: "Yuqing Liu"
date: "2023-09-27"
output: github_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r library, include=FALSE}
library(tidyverse)
library(readxl)
```

# Problem 1
### pols-month.csv
clean the data in pols-month:

* import the dataset by `read.csv()`
* clean up the names by `janitor::clean_names()`
* separate the date variable `mon` into `year`,`month`,`day` by `separate()`, and match the number of month with the abbreviated month in character by `case_match()`
* create a `president` variable taking values gop and dem by `case_match()`
* check the first six rows of the dataset using `head()` because the data will be very long after knit if presented

```{r import and clean pols-month.csv dataset}
pols_month = read.csv(file = "./fivethirtyeight_datasets/pols-month.csv") |> janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"))|>
  mutate(
    month =
      case_match(
        month,
        "01" ~ "jan",
        "02" ~ "feb",
        "03" ~ "mar",
        "04" ~ "apr",
        "05" ~ "may",
        "06" ~ "jun",
        "07" ~ "jul",
        "08" ~ "aug",
        "09" ~ "sep",
        "10" ~ "oct",
        "11" ~ "nov",
        "12" ~ "dec")
      )|>
  mutate(president=case_match(
           prez_dem,
           1~"democratic",
           0~"republican"))  |>
  select(-prez_dem, -prez_gop, -day)

head(pols_month)
```


### snp.csv
clean and check the data in snp:

* import the dataset by `read.csv()`
* clean up the names by `janitor::clean_names()`
* separate the date variable `mon` into `year`,`month`,`day` by `separate()`, and match the number of month with the abbreviated month in character by `case_match()`
* remove `day` by `select(-day)`
* organize so that year and month are the leading columns by `select(year, month, everything())`

```{r import and clean snp.csv dataset}
snp = read.csv(file = "./fivethirtyeight_datasets/snp.csv")|>
  janitor::clean_names()|>
  separate(date, into = c("month", "day", "year"))|>
  mutate(
    month =
      case_match(
        month,
        "1" ~ "jan",
        "2" ~ "feb",
        "3" ~ "mar",
        "4" ~ "apr",
        "5" ~ "may",
        "6" ~ "jun",
        "7" ~ "jul",
        "8" ~ "aug",
        "9" ~ "sep",
        "10" ~ "oct",
        "11" ~ "nov",
        "12" ~ "dec")
      )|>select(-day)|>
  select(year, month, everything())

head(snp)
```

### unemployment.csv
clean and check the data in unemployment:

* import the dataset by `read.csv()`
* clean up the names by `janitor::clean_names()`
* switch from “wide” to “long” format by `pivot_longer()`
* turn `year` into a character variable by `mutate(year=as.character(year))`

```{r import and clean unemployment.csv dataset}
unemployment = read.csv(file = "./fivethirtyeight_datasets/unemployment.csv")|>
  janitor::clean_names()|>
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment")|>
    mutate(year=as.character(year))

head(unemployment)
```
### merge datasets
join the datasets:

* merge snp into pols, and merge unemployment into the result by `left_join()`

```{r}
df=pols_month|>
  left_join(snp,by=c("year", "month"))|>
  left_join(unemployment, by=c("year", "month"))

head(df)
```

### Discussion
* The dataset `pols_month` contains `r nrow(pols_month)` rows and `r ncol(pols_month)` columns. It contains variables including `year`, `month`, `gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`, `rep_dem`, `president`. The range of `year` is from `r pols_month |> pull(year) |> min()` to `r pols_month |> pull(year) |> max()`.



* The dataset `snp` contains `r nrow(snp)` rows and `r ncol(snp)` columns. It contains variables including `year`, `month`, `close`.The range of `year` is from `r snp |> pull(year) |> min()` to `r snp |> pull(year) |> max()`.

* The dataset `unemployment` contains `r nrow(unemployment)` rows and `r ncol(unemployment)` columns. It contains variables including `year`, `month`, `unemployment`.The range of `year` is from `r unemployment |> pull(year) |> min()` to `r unemployment |> pull(year) |> max()`.

* The merged dataset `df` contains `r nrow(df)` rows and `r ncol(df)` columns. It contains variables including `year`, `month`, `gov_gop`, `sen_gop`, `rep_gop`, `gov_dem`, `sen_dem`, `rep_dem`, `president`, `close`.The range of `year` is from `r df |> pull(year) |> min()` to `r df |> pull(year) |> max()`.


# Problem 2
### Mr.Trash Wheel

Below we read and clean Mr. Trash Wheel dataset:

* specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in `read_excel()`
* use reasonable variable names by `janitor::clean_names()`
* omit rows that do not include dumpster-specific data by ` filter(row_number() <= n()-1)` to delete the last row
* Home power notes mentioned each ton of trash equates to on average 500 kilowatts of electricity and an average household will use 30 kilowatts per day. Based on this information, we can calculate the number of homes powered by Mr. Trash Wheel `homes_powered` by `mutate(homes_powered=weight_tons*500/30)`.

```{r}
mr_trash_wheel = read_excel("./202309 Trash Wheel Collection Data.xlsx", 
                            sheet="Mr. Trash Wheel", 
                            range = cell_cols("A:N"))|>
  janitor::clean_names()|> 
  filter(row_number() <= n()-1)|>
  mutate(homes_powered=weight_tons*500/30)

mr_trash_wheel
```

### Professor Trash Wheel

We use the same methods for Professor Trash Wheel sheet:

* specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in `read_excel()`
* use reasonable variable names by `janitor::clean_names()`
* omit rows that do not include dumpster-specific data by ` filter(row_number() <= n()-1)` to delete the last row
* Home power notes mentioned each ton of trash equates to on average 500 kilowatts of electricity and an average household will use 30 kilowatts per day. Based on this information, we can calculate the number of homes powered by Mr. Trash Wheel `homes_powered` by `mutate(homes_powered=weight_tons*500/30)`.

```{r message=FALSE}
professor_trash_wheel = read_excel("./202309 Trash Wheel Collection Data.xlsx", 
                                   sheet="Professor Trash Wheel", 
                                   range = cell_cols("A:M"))|>
  janitor::clean_names()|> 
  filter(row_number() <= n()-1)|>
  mutate(homes_powered=weight_tons*500/30)

professor_trash_wheel
```

### Gwynnda

We use the same methods for Gwynnda Trash Wheel sheet:

* specify the sheet in the Excel file and to omit non-data entries (rows with notes / figures; columns containing notes) using arguments in `read_excel()`
* use reasonable variable names by `janitor::clean_names()`
* omit rows that do not include dumpster-specific data by ` filter(row_number() <= n()-2)` to delete the last two rows
* Home power notes mentioned each ton of trash equates to on average 500 kilowatts of electricity and an average household will use 30 kilowatts per day. Based on this information, we can calculate the number of homes powered by Mr. Trash Wheel `homes_powered` by `mutate(homes_powered=weight_tons*500/30)`.

```{r message=FALSE}
gwynnda_trash_wheel = read_excel("./202309 Trash Wheel Collection Data.xlsx", 
                                   sheet="Gwynnda Trash Wheel", 
                                   range = cell_cols("A:L"))|>
  janitor::clean_names()|> 
  filter(row_number() <= n()-2)|>
  mutate(homes_powered=weight_tons*500/30)

gwynnda_trash_wheel
```
### Combine datasets

* We first create a additional variable `trash_wheel_type` to all datasets to keep track of which is originated from which Trash Wheel dataset. 

* Combine the three Trash Wheel datasets to produce a single tidy dataset `trash_wheel_merged`. 

```{r}
mr_trash_wheel=mr_trash_wheel|>
  mutate(trash_wheel_type="Mr Trash Wheel")

professor_trash_wheel=professor_trash_wheel|>
  mutate(trash_wheel_type="Professor Trash Wheel",
         year=as.character(year))

gwynnda_trash_wheel=gwynnda_trash_wheel|>
  mutate(trash_wheel_type="Gwynnda Trash Wheel",
         year=as.character(year))

trash_wheel_merged = 
  bind_rows(mr_trash_wheel, professor_trash_wheel, gwynnda_trash_wheel) |>
  janitor::clean_names() |>
  select(trash_wheel_type, everything()) 

trash_wheel_merged
```

### Discussion

* The resulting dataset has `r nrow(trash_wheel_merged)` rows and `r ncol(trash_wheel_merged)` columns. So, it has `r nrow(trash_wheel_merged)` observations. 

* The key variables includes `trash_wheel_type`, `dumpster`, `month`, `year`, `date`, `weight_tons`, `volume_cubic_yards`, `plastic_bottles`, `polystyrene`, `cigarette_butts`, `glass_bottles`, `plastic_bags`, `wrappers`, `sports_balls`, `homes_powered`.

* The total weight of trash collected by Professor Trash Wheel is `r sum(professor_trash_wheel$weight_tons)` tons.

* The total number of cigarette butts collected by Gwynnda in July of 2021 is `r sum(subset(gwynnda_trash_wheel, month == "July" & year == "2021" )$cigarette_butts)`.

# Problem 3
### MCI_baseline

* Import the dataset `MCI_baseline.csv` using `read.csv()`. Skip the first row by `skip=1`.
* Clean variables names by `janitor::clean_names()`.
* Make sure sex is appropriate encoded (i.e. not numeric) by matching 1 to male and 0 to female, and make `sex` as a factor variable through `mutate(sex = case_match(sex, 1 ~ "male", 0 ~ "female"), sex = as.factor(sex))`.
* Make sure APOE4 carrier status is appropriate encoded (i.e. not numeric) by matching 1 to apoe4 carrier and 0 to apoe4 non-carrier, and make `apeo4` as a factor variable through `mutate(apoe4 = case_match(apoe4, 1 ~ "apoe4 carrier", 0 ~ "apoe4 non-carrier"), apoe4 = as.factor(apoe4))`.
* Remove any participants who do not meet the stated inclusion criteria (i.e. no MCI at baseline) by dropping observations with missing value in `age_at_onset` by replacing . with NA and then `drop_na()`.

```{r}
mci_baseline = read.csv(file = "./data_mci/MCI_baseline.csv", skip=1) |> janitor::clean_names()|>
    mutate(
    sex = 
      case_match(
        sex, 
        1 ~ "male", 
        0 ~ "female"),
    sex = as.factor(sex),
    apoe4 = 
      case_match(
        apoe4,
        1 ~ "apoe4 carrier",
        0 ~ "apoe4 non-carrier"),
    apoe4 = as.factor(apoe4),
    age_at_onset = ifelse(age_at_onset==".", NA, age_at_onset)
    ) |>
  drop_na(age_at_onset)

head(mci_baseline)
```

### Discussion 

Important steps in the import process:

* `skip=1` skips the first line of the explanation of variables when importing dataset
* `janitor::clean_names()`converts all the variable names to lower case
* `case_match` rewrites sex and apoe4 into what they represent and matches their meanings into their values respectively
* `drop_na(age_at_onset)`removes the row with missing value in `age_at_onset`. `drop_na` only recognizes values with NA rather than . So, we need to convert `.` to `NA` using a `ifelse()` statement before dropping NA. 

Relevant features of the dataset:

* The dataset has `r nrow(mci_baseline)` observations and `r ncol(mci_baseline)` variables.
* The dataset has variables including `id`, `current_age`, `sex`,`education`, `apoe4` (whether a person is apoe4 carrier or non-carrier), `age_at_onset`.

Answering the questions:

* From the number of observations in the raw dataset before data cleaning, we know there were 483 participants that were recruited.
* After data cleaning, we know `r nrow(mci_baseline)` of the total participants developed MCI.
* The average baseline age is `r round(mean(pull(mci_baseline, current_age), na.rm = TRUE),2)`
years old. 
* The proportion of women in the study that are APOE4 carriers P(apoe4 carriers|women developed mci) = `r round(nrow(mci_baseline[mci_baseline$sex == 'female' & mci_baseline$apoe4 =='apoe4 carrier', ]) / nrow(mci_baseline[mci_baseline$sex == 'female', ]),4) `.

### Biomarker

Similarly, import, clean, and tidy the dataset of longitudinally observed biomarker values

* Import the dataset `MCI_baseline.csv` using `read.csv()`. Skip the first row by `skip=1`.
* Clean variables names by `janitor::clean_names()`.
* Unify the id used in the study as `id` by `rename(id=study_id)`.

```{r}
mci_amyloid = read.csv(file = "./data_mci/mci_amyloid.csv", skip=1) |> janitor::clean_names()|>
  rename(id=study_id)
  
head(mci_amyloid)
```
Important steps in the import process:

* `skip=1` skips the first line of the explanation of variables when importing dataset
* `janitor::clean_names()`: convert all the variable names to lower case

The features of the dataset:

* The dataset has `r nrow(mci_amyloid)` observations and `r ncol(mci_amyloid)` variables.
* The dataset has variables including  `id`, `baseline`, `time_2`, `time_4`, `time_6`, `time_8`

### Check whether some participants appear in only one dataset

* check participants that appear in only the baseline by `anti_join`

```{r}
only_mci_baseline <- anti_join(mci_baseline, mci_amyloid, by = "id")

only_mci_baseline
```

* check participants that appear in only the amyloid by `anti_join` (the dataset is too long so I used `head()`)

```{r}
only_mci_amyloid <- anti_join(mci_amyloid, mci_baseline, by = "id")

head(only_mci_amyloid)
```
* In conclusion, `r nrow(only_mci_baseline)` participants appears only in the baseline, and`r nrow(only_mci_amyloid)` participants appears only in the baseline. There do exist participants that appear in only the baseline or amyloid datasets.

### Combine datasets

Combine the demographic and biomarker datasets 

* combine the datasets by `inner_join()` so that only participants who appear in both datasets are retained
* examine the merged dataset by `head()` because the dataset is too long

```{r}
mci_merged = inner_join(mci_baseline, mci_amyloid, by = "id")

head(mci_merged)
```


### Describe the resulting dataset

* The resulting dataset `mci_merged` includes `r nrow(mci_merged)` observations, with `r ncol(mci_merged)` variables.
* The `mci_merged` dataset has variables including `id`, `current_age`, `sex`, `educations`, `apoe4` (whether a person is an apoe4 carrier or non-carrier), `age_at_onset`, `baseline`, `time_2`, `time_4`, `time_6`, `time_8`.


### Export the result

* export the `mci_merged` dataset as a cvs file by `write.csv`

```{r}
write.csv(mci_merged, file = "./data_mci/mci_merged.csv", row.names = FALSE)
```


