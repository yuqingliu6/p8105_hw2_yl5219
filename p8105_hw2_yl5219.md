p8105_hw2_yl5219
================
Yuqing Liu
2023-09-27

# Problem 1

### pols-month.csv

clean the data in pols-month:

- import the dataset by `read.csv()`
- clean up the names by `janitor::clean_names()`
- separate the date variable `mon` into `year`,`month`,`day` by
  `separate()`, and match the number of month with the abbreviated month
  in character by `case_match()`
- create a `president` variable taking values gop and dem by
  `case_match()`
- check the first six rows of the dataset using `head()` because the
  data will be very long after knit if presented

``` r
pols_month = read.csv(file = "./fivethirtyeight_datasets/pols-month.csv") |> janitor::clean_names() |>
  separate(mon, into = c("year", "month", "day"))|>
  mutate(
    month =
      case_match(
        month,
        "01" ~ "jan",
        "02" ~ "feb",
        "03" ~ "mar",
        "04" ~ "apr",
        "05" ~ "may",
        "06" ~ "jun",
        "07" ~ "jul",
        "08" ~ "aug",
        "09" ~ "sep",
        "10" ~ "oct",
        "11" ~ "nov",
        "12" ~ "dec")
      )|>
  mutate(president=case_match(
           prez_dem,
           1~"democratic",
           0~"republican"))  |>
  select(-prez_dem, -prez_gop, -day)

head(pols_month)
```

    ##   year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem  president
    ## 1 1947   jan      23      51     253      23      45     198 democratic
    ## 2 1947   feb      23      51     253      23      45     198 democratic
    ## 3 1947   mar      23      51     253      23      45     198 democratic
    ## 4 1947   apr      23      51     253      23      45     198 democratic
    ## 5 1947   may      23      51     253      23      45     198 democratic
    ## 6 1947   jun      23      51     253      23      45     198 democratic

### snp.csv

clean and check the data in snp:

- import the dataset by `read.csv()`
- clean up the names by `janitor::clean_names()`
- separate the date variable `mon` into `year`,`month`,`day` by
  `separate()`, and match the number of month with the abbreviated month
  in character by `case_match()`
- remove `day` by `select(-day)`
- organize so that year and month are the leading columns by
  `select(year, month, everything())`

``` r
snp = read.csv(file = "./fivethirtyeight_datasets/snp.csv")|>
  janitor::clean_names()|>
  separate(date, into = c("month", "day", "year"))|>
  mutate(
    month =
      case_match(
        month,
        "1" ~ "jan",
        "2" ~ "feb",
        "3" ~ "mar",
        "4" ~ "apr",
        "5" ~ "may",
        "6" ~ "jun",
        "7" ~ "jul",
        "8" ~ "aug",
        "9" ~ "sep",
        "10" ~ "oct",
        "11" ~ "nov",
        "12" ~ "dec")
      )|>select(-day)|>
  select(year, month, everything())

head(snp)
```

    ##   year month   close
    ## 1   15   jul 2079.65
    ## 2   15   jun 2063.11
    ## 3   15   may 2107.39
    ## 4   15   apr 2085.51
    ## 5   15   mar 2067.89
    ## 6   15   feb 2104.50

### unemployment.csv

clean and check the data in unemployment:

- import the dataset by `read.csv()`
- clean up the names by `janitor::clean_names()`
- switch from “wide” to “long” format by `pivot_longer()`
- turn `year` into a character variable by
  `mutate(year=as.character(year))`

``` r
unemployment = read.csv(file = "./fivethirtyeight_datasets/unemployment.csv")|>
  janitor::clean_names()|>
  pivot_longer(
    jan:dec,
    names_to = "month",
    values_to = "unemployment")|>
    mutate(year=as.character(year))

head(unemployment)
```

    ## # A tibble: 6 × 3
    ##   year  month unemployment
    ##   <chr> <chr>        <dbl>
    ## 1 1948  jan            3.4
    ## 2 1948  feb            3.8
    ## 3 1948  mar            4  
    ## 4 1948  apr            3.9
    ## 5 1948  may            3.5
    ## 6 1948  jun            3.6

### merge datasets

join the datasets:

- merge snp into pols, and merge unemployment into the result by
  `left_join()`

``` r
df=pols_month|>
  left_join(snp,by=c("year", "month"))|>
  left_join(unemployment, by=c("year", "month"))

head(df)
```

    ##   year month gov_gop sen_gop rep_gop gov_dem sen_dem rep_dem  president close
    ## 1 1947   jan      23      51     253      23      45     198 democratic    NA
    ## 2 1947   feb      23      51     253      23      45     198 democratic    NA
    ## 3 1947   mar      23      51     253      23      45     198 democratic    NA
    ## 4 1947   apr      23      51     253      23      45     198 democratic    NA
    ## 5 1947   may      23      51     253      23      45     198 democratic    NA
    ## 6 1947   jun      23      51     253      23      45     198 democratic    NA
    ##   unemployment
    ## 1           NA
    ## 2           NA
    ## 3           NA
    ## 4           NA
    ## 5           NA
    ## 6           NA

### Discussion

- The dataset `pols_month` contains 822 rows and 9 columns. It contains
  variables including `year`, `month`, `gov_gop`, `sen_gop`, `rep_gop`,
  `gov_dem`, `sen_dem`, `rep_dem`, `president`. The range of `year` is
  from 1947 to 2015.

- The dataset `snp` contains 787 rows and 3 columns. It contains
  variables including `year`, `month`, `close`.The range of `year` is
  from 00 to 99.

- The dataset `unemployment` contains 816 rows and 3 columns. It
  contains variables including `year`, `month`, `unemployment`.The range
  of `year` is from 1948 to 2015.

- The merged dataset `df` contains 822 rows and 11 columns. It contains
  variables including `year`, `month`, `gov_gop`, `sen_gop`, `rep_gop`,
  `gov_dem`, `sen_dem`, `rep_dem`, `president`, `close`.The range of
  `year` is from 1947 to 2015.

# Problem 2

### Mr.Trash Wheel

Below we read and clean Mr. Trash Wheel dataset:

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  `read_excel()`
- use reasonable variable names by `janitor::clean_names()`
- omit rows that do not include dumpster-specific data by
  `filter(row_number() <= n()-1)` to delete the last row
- Home power notes mentioned each ton of trash equates to on average 500
  kilowatts of electricity and an average household will use 30
  kilowatts per day. Based on this information, we can calculate the
  number of homes powered by Mr. Trash Wheel `homes_powered` by
  `mutate(homes_powered=weight_tons*500/30)`.

``` r
mr_trash_wheel = read_excel("./202309 Trash Wheel Collection Data.xlsx", 
                            sheet="Mr. Trash Wheel", 
                            range = cell_cols("A:N"))|>
  janitor::clean_names()|> 
  filter(row_number() <= n()-1)|>
  mutate(homes_powered=weight_tons*500/30)

mr_trash_wheel
```

    ## # A tibble: 584 × 14
    ##    dumpster month year  date                weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <dttm>                    <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16 00:00:00        4.31                 18
    ##  2        2 May   2014  2014-05-16 00:00:00        2.74                 13
    ##  3        3 May   2014  2014-05-16 00:00:00        3.45                 15
    ##  4        4 May   2014  2014-05-17 00:00:00        3.1                  15
    ##  5        5 May   2014  2014-05-17 00:00:00        4.06                 18
    ##  6        6 May   2014  2014-05-20 00:00:00        2.71                 13
    ##  7        7 May   2014  2014-05-21 00:00:00        1.91                  8
    ##  8        8 May   2014  2014-05-28 00:00:00        3.7                  16
    ##  9        9 June  2014  2014-06-05 00:00:00        2.52                 14
    ## 10       10 June  2014  2014-06-11 00:00:00        3.76                 18
    ## # ℹ 574 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

### Professor Trash Wheel

We use the same methods for Professor Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  `read_excel()`
- use reasonable variable names by `janitor::clean_names()`
- omit rows that do not include dumpster-specific data by
  `filter(row_number() <= n()-1)` to delete the last row
- Home power notes mentioned each ton of trash equates to on average 500
  kilowatts of electricity and an average household will use 30
  kilowatts per day. Based on this information, we can calculate the
  number of homes powered by Mr. Trash Wheel `homes_powered` by
  `mutate(homes_powered=weight_tons*500/30)`.

``` r
professor_trash_wheel = read_excel("./202309 Trash Wheel Collection Data.xlsx", 
                                   sheet="Professor Trash Wheel", 
                                   range = cell_cols("A:M"))|>
  janitor::clean_names()|> 
  filter(row_number() <= n()-1)|>
  mutate(homes_powered=weight_tons*500/30)

professor_trash_wheel
```

    ## # A tibble: 106 × 13
    ##    dumpster month     year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>    <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 January   2017 2017-01-02 00:00:00        1.79                 15
    ##  2        2 January   2017 2017-01-30 00:00:00        1.58                 15
    ##  3        3 February  2017 2017-02-26 00:00:00        2.32                 18
    ##  4        4 February  2017 2017-02-26 00:00:00        3.72                 15
    ##  5        5 February  2017 2017-02-28 00:00:00        1.45                 15
    ##  6        6 March     2017 2017-03-30 00:00:00        1.71                 15
    ##  7        7 April     2017 2017-04-01 00:00:00        1.82                 15
    ##  8        8 April     2017 2017-04-20 00:00:00        2.37                 15
    ##  9        9 May       2017 2017-05-10 00:00:00        2.64                 15
    ## 10       10 May       2017 2017-05-26 00:00:00        2.78                 15
    ## # ℹ 96 more rows
    ## # ℹ 7 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, homes_powered <dbl>

### Gwynnda

We use the same methods for Gwynnda Trash Wheel sheet:

- specify the sheet in the Excel file and to omit non-data entries (rows
  with notes / figures; columns containing notes) using arguments in
  `read_excel()`
- use reasonable variable names by `janitor::clean_names()`
- omit rows that do not include dumpster-specific data by
  `filter(row_number() <= n()-2)` to delete the last two rows
- Home power notes mentioned each ton of trash equates to on average 500
  kilowatts of electricity and an average household will use 30
  kilowatts per day. Based on this information, we can calculate the
  number of homes powered by Mr. Trash Wheel `homes_powered` by
  `mutate(homes_powered=weight_tons*500/30)`.

``` r
gwynnda_trash_wheel = read_excel("./202309 Trash Wheel Collection Data.xlsx", 
                                   sheet="Gwynnda Trash Wheel", 
                                   range = cell_cols("A:L"))|>
  janitor::clean_names()|> 
  filter(row_number() <= n()-2)|>
  mutate(homes_powered=weight_tons*500/30)

gwynnda_trash_wheel
```

    ## # A tibble: 155 × 12
    ##    dumpster month   year date                weight_tons volume_cubic_yards
    ##       <dbl> <chr>  <dbl> <dttm>                    <dbl>              <dbl>
    ##  1        1 July    2021 2021-07-03 00:00:00        0.93                 15
    ##  2        2 July    2021 2021-07-07 00:00:00        2.26                 15
    ##  3        3 July    2021 2021-07-07 00:00:00        1.62                 15
    ##  4        4 July    2021 2021-07-16 00:00:00        1.76                 15
    ##  5        5 July    2021 2021-07-30 00:00:00        1.53                 15
    ##  6        6 August  2021 2021-08-11 00:00:00        2.06                 15
    ##  7        7 August  2021 2021-08-14 00:00:00        1.9                  15
    ##  8        8 August  2021 2021-08-16 00:00:00        2.16                 15
    ##  9        9 August  2021 2021-08-16 00:00:00        2.6                  15
    ## 10       10 August  2021 2021-08-17 00:00:00        3.21                 15
    ## # ℹ 145 more rows
    ## # ℹ 6 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   homes_powered <dbl>

### Combine datasets

- We first create a additional variable `trash_wheel_type` to all
  datasets to keep track of which is originated from which Trash Wheel
  dataset.

- Combine the three Trash Wheel datasets to produce a single tidy
  dataset `trash_wheel_merged`.

``` r
mr_trash_wheel=mr_trash_wheel|>
  mutate(trash_wheel_type="Mr Trash Wheel")

professor_trash_wheel=professor_trash_wheel|>
  mutate(trash_wheel_type="Professor Trash Wheel",
         year=as.character(year))

gwynnda_trash_wheel=gwynnda_trash_wheel|>
  mutate(trash_wheel_type="Gwynnda Trash Wheel",
         year=as.character(year))

trash_wheel_merged = 
  bind_rows(mr_trash_wheel, professor_trash_wheel, gwynnda_trash_wheel) |>
  janitor::clean_names() |>
  select(trash_wheel_type, everything()) 

trash_wheel_merged
```

    ## # A tibble: 845 × 15
    ##    trash_wheel_type dumpster month year  date                weight_tons
    ##    <chr>               <dbl> <chr> <chr> <dttm>                    <dbl>
    ##  1 Mr Trash Wheel          1 May   2014  2014-05-16 00:00:00        4.31
    ##  2 Mr Trash Wheel          2 May   2014  2014-05-16 00:00:00        2.74
    ##  3 Mr Trash Wheel          3 May   2014  2014-05-16 00:00:00        3.45
    ##  4 Mr Trash Wheel          4 May   2014  2014-05-17 00:00:00        3.1 
    ##  5 Mr Trash Wheel          5 May   2014  2014-05-17 00:00:00        4.06
    ##  6 Mr Trash Wheel          6 May   2014  2014-05-20 00:00:00        2.71
    ##  7 Mr Trash Wheel          7 May   2014  2014-05-21 00:00:00        1.91
    ##  8 Mr Trash Wheel          8 May   2014  2014-05-28 00:00:00        3.7 
    ##  9 Mr Trash Wheel          9 June  2014  2014-06-05 00:00:00        2.52
    ## 10 Mr Trash Wheel         10 June  2014  2014-06-11 00:00:00        3.76
    ## # ℹ 835 more rows
    ## # ℹ 9 more variables: volume_cubic_yards <dbl>, plastic_bottles <dbl>,
    ## #   polystyrene <dbl>, cigarette_butts <dbl>, glass_bottles <dbl>,
    ## #   plastic_bags <dbl>, wrappers <dbl>, sports_balls <dbl>, homes_powered <dbl>

### Discussion

- The resulting dataset has 845 rows and 15 columns. So, it has 845
  observations.

- The key variables includes `trash_wheel_type`, `dumpster`, `month`,
  `year`, `date`, `weight_tons`, `volume_cubic_yards`,
  `plastic_bottles`, `polystyrene`, `cigarette_butts`, `glass_bottles`,
  `plastic_bags`, `wrappers`, `sports_balls`, `homes_powered`.

- The total weight of trash collected by Professor Trash Wheel is 216.26
  tons.

- The total number of cigarette butts collected by Gwynnda in July of
  2021 is 1.63^{4}.

# Problem 3

### MCI_baseline

- Import the dataset `MCI_baseline.csv` using `read.csv()`. Skip the
  first row by `skip=1`.
- Clean variables names by `janitor::clean_names()`.
- Make sure sex is appropriate encoded (i.e. not numeric) by matching 1
  to male and 0 to female, and make `sex` as a factor variable through
  `mutate(sex = case_match(sex, 1 ~ "male", 0 ~ "female"), sex = as.factor(sex))`.
- Make sure APOE4 carrier status is appropriate encoded (i.e. not
  numeric) by matching 1 to apoe4 carrier and 0 to apoe4 non-carrier,
  and make `apeo4` as a factor variable through
  `mutate(apoe4 = case_match(apoe4, 1 ~ "apoe4 carrier", 0 ~ "apoe4 non-carrier"), apoe4 = as.factor(apoe4))`.
- Remove any participants who do not meet the stated inclusion criteria
  (i.e. no MCI at baseline) by dropping observations with missing value
  in `age_at_onset` by replacing . with NA and then `drop_na()`.

``` r
mci_baseline = read.csv(file = "./data_mci/MCI_baseline.csv", skip=1) |> janitor::clean_names()|>
    mutate(
    sex = 
      case_match(
        sex, 
        1 ~ "male", 
        0 ~ "female"),
    sex = as.factor(sex),
    apoe4 = 
      case_match(
        apoe4,
        1 ~ "apoe4 carrier",
        0 ~ "apoe4 non-carrier"),
    apoe4 = as.factor(apoe4),
    age_at_onset = ifelse(age_at_onset==".", NA, age_at_onset)
    ) |>
  drop_na(age_at_onset)

head(mci_baseline)
```

    ##   id current_age    sex education             apoe4 age_at_onset
    ## 1  3        62.5   male        16     apoe4 carrier         66.8
    ## 2  5        66.0   male        16 apoe4 non-carrier         68.7
    ## 3  7        66.5   male        18 apoe4 non-carrier           74
    ## 4 13        63.1   male        12     apoe4 carrier           69
    ## 5 14        58.4 female        20 apoe4 non-carrier         66.2
    ## 6 18        67.8   male        16 apoe4 non-carrier         69.8

### Discussion

Important steps in the import process:

- `skip=1` skips the first line of the explanation of variables when
  importing dataset
- `janitor::clean_names()`converts all the variable names to lower case
- `case_match` rewrites sex and apoe4 into what they represent and
  matches their meanings into their values respectively
- `drop_na(age_at_onset)`removes the row with missing value in
  `age_at_onset`. `drop_na` only recognizes values with NA rather than .
  So, we need to convert `.` to `NA` using a `ifelse()` statement before
  dropping NA.

Relevant features of the dataset:

- The dataset has 97 observations and 6 variables.
- The dataset has variables including `id`, `current_age`,
  `sex`,`education`, `apoe4` (whether a person is apoe4 carrier or
  non-carrier), `age_at_onset`.

Answering the questions:

- From the number of observations in the raw dataset before data
  cleaning, we know there were 483 participants that were recruited.
- After data cleaning, we know 97 of the total participants developed
  MCI.
- The average baseline age is 65.61 years old.
- The proportion of women in the study that are APOE4 carriers P(apoe4
  carriers\|women developed mci) = 0.6522.

### Biomarker

Similarly, import, clean, and tidy the dataset of longitudinally
observed biomarker values

- Import the dataset `MCI_baseline.csv` using `read.csv()`. Skip the
  first row by `skip=1`.
- Clean variables names by `janitor::clean_names()`.
- Unify the id used in the study as `id` by `rename(id=study_id)`.

``` r
mci_amyloid = read.csv(file = "./data_mci/mci_amyloid.csv", skip=1) |> janitor::clean_names()|>
  rename(id=study_id)
  
head(mci_amyloid)
```

    ##   id    baseline      time_2      time_4      time_6      time_8
    ## 1  1   0.1105487        <NA> 0.109325197 0.104756131 0.107257697
    ## 2  2 0.107481183 0.109157373 0.109457839 0.105729713  0.10661845
    ## 3  3 0.106087034 0.108744509 0.106065035        <NA> 0.106152357
    ## 4  4 0.109251358 0.108699686 0.110540386 0.107476797 0.111212209
    ## 5  5 0.107950408 0.112273883 0.115139677 0.106606054 0.106052066
    ## 6  6 0.112426974 0.112853415  0.11143945 0.110279277 0.114982747

Important steps in the import process:

- `skip=1` skips the first line of the explanation of variables when
  importing dataset
- `janitor::clean_names()`: convert all the variable names to lower case

The features of the dataset:

- The dataset has 487 observations and 6 variables.
- The dataset has variables including `id`, `baseline`, `time_2`,
  `time_4`, `time_6`, `time_8`

### Check whether some participants appear in only one dataset

- check participants that appear in only the baseline by `anti_join`

``` r
only_mci_baseline <- anti_join(mci_baseline, mci_amyloid, by = "id")

only_mci_baseline
```

    ##    id current_age    sex education             apoe4 age_at_onset
    ## 1  14        58.4 female        20 apoe4 non-carrier         66.2
    ## 2  49        64.7   male        16 apoe4 non-carrier         68.4
    ## 3 268        61.4 female        18     apoe4 carrier         67.5

- check participants that appear in only the amyloid by `anti_join` (the
  dataset is too long so I used `head()`)

``` r
only_mci_amyloid <- anti_join(mci_amyloid, mci_baseline, by = "id")

head(only_mci_amyloid)
```

    ##   id    baseline      time_2      time_4      time_6      time_8
    ## 1  1   0.1105487        <NA> 0.109325197 0.104756131 0.107257697
    ## 2  2 0.107481183 0.109157373 0.109457839 0.105729713  0.10661845
    ## 3  4 0.109251358 0.108699686 0.110540386 0.107476797 0.111212209
    ## 4  6 0.112426974 0.112853415  0.11143945 0.110279277 0.114982747
    ## 5  8 0.109563372 0.109470828        <NA> 0.108742168 0.110268552
    ## 6  9 0.112101884 0.109781199 0.108832888        <NA>        <NA>

- In conclusion, 3 participants appears only in the baseline, and393
  participants appears only in the baseline. There do exist participants
  that appear in only the baseline or amyloid datasets.

### Combine datasets

Combine the demographic and biomarker datasets

- combine the datasets by `inner_join()` so that only participants who
  appear in both datasets are retained
- examine the merged dataset by `head()` because the dataset is too long

``` r
mci_merged = inner_join(mci_baseline, mci_amyloid, by = "id")

head(mci_merged)
```

    ##   id current_age    sex education             apoe4 age_at_onset    baseline
    ## 1  3        62.5   male        16     apoe4 carrier         66.8 0.106087034
    ## 2  5        66.0   male        16 apoe4 non-carrier         68.7 0.107950408
    ## 3  7        66.5   male        18 apoe4 non-carrier           74 0.112246391
    ## 4 13        63.1   male        12     apoe4 carrier           69 0.110300505
    ## 5 18        67.8   male        16 apoe4 non-carrier         69.8 0.114137255
    ## 6 22        67.3 female        20     apoe4 carrier         74.6 0.109320501
    ##        time_2      time_4      time_6      time_8
    ## 1 0.108744509 0.106065035        <NA> 0.106152357
    ## 2 0.112273883 0.115139677 0.106606054 0.106052066
    ## 3        <NA> 0.104251905 0.112485583 0.112055612
    ## 4 0.108534417 0.108100808 0.109229662 0.104861901
    ## 5 0.107093264 0.110872562 0.108982605 0.106873903
    ## 6        <NA> 0.107524961 0.106098161 0.105416197

### Describe the resulting dataset

- The resulting dataset `mci_merged` includes 94 observations, with 11
  variables.
- The `mci_merged` dataset has variables including `id`, `current_age`,
  `sex`, `educations`, `apoe4` (whether a person is an apoe4 carrier or
  non-carrier), `age_at_onset`, `baseline`, `time_2`, `time_4`,
  `time_6`, `time_8`.

### Export the result

- export the `mci_merged` dataset as a cvs file by `write.csv`

``` r
write.csv(mci_merged, file = "./data_mci/mci_merged.csv", row.names = FALSE)
```
